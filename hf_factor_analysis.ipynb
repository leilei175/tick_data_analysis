{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中证1000高频因子分析\n",
    "\n",
    "## 分析目标\n",
    "\n",
    "分析各类高频因子对中证1000成分股（1000只股票）未来收益的预测效果\n",
    "\n",
    "## 高频因子列表\n",
    "\n",
    "| 因子名称 | 英文名 | 计算公式 |\n",
    "|---------|--------|----------|\n",
    "| 订单不平衡因子 | order_imbalance | (BidVol - AskVol) / (BidVol + AskVol) |\n",
    "| 有效价差因子 | effective_spread | 2 * |MidPrice - TradePrice| / MidPrice |\n",
    "| 已实现波动率 | realized_volatility | sqrt(sum(log(price_t/price_{t-1})^2)) |\n",
    "| 买卖价差因子 | bid_ask_spread | Ask1 - Bid1 |\n",
    "| VWAP偏离因子 | vwap_deviation | (Price - VWAP) / VWAP |\n",
    "| 价格动量因子 | price_momentum | Price_t / Price_{t-n} - 1 |\n",
    "| 订单流强度 | trade_flow_intensity | 单位时间交易量变化 |\n",
    "| 微价格因子 | micro_price | (Bid1*AskVol + Ask1*BidVol) / (BidVol + AskVol) |\n",
    "| 交易不平衡 | trade_imbalance | 主动买/卖量差占比 |\n",
    "| 深度不平衡 | depth_imbalance | 深度加权价格不平衡度 |\n",
    "\n",
    "---\n",
    "\n",
    "**数据概况**\n",
    "- 股票数量: 1000只\n",
    "- 时间范围: 2025-12-01 ~ 2026-02-06\n",
    "- 高频记录数: 104,735,954条\n",
    "- 日度因子数: 27,705条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "库导入成功!\n",
      "pandas: 1.5.3, numpy: 1.22.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"库导入成功!\")\n",
    "print(f\"pandas: {pd.__version__}, numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025_12_15.parquet', '2026_01_09.parquet', '2026_01_05.parquet', '2026_01_21.parquet', '2026_01_28.parquet', '2025_12_23.parquet', '2026_01_30.parquet', '2025_12_11.parquet', '2026_01_29.parquet', '2025_12_04.parquet', '2026_01_15.parquet', '2026_01_06.parquet', '2026_01_07.parquet', '2026_02_09.parquet', '2026_01_14.parquet', '2025_11_04.parquet', '2026_02_03.parquet', '2026_01_19.parquet', '2026_02_05.parquet', '2026_01_22.parquet', '2026_01_27.parquet', '2026_01_12.parquet', '2025_12_19.parquet', '2025_12_03.parquet', '2025_12_17.parquet', '2026_02_04.parquet', '2025_12_22.parquet', '2025_12_08.parquet', '2026_01_16.parquet', '2026_02_06.parquet', '2026_01_20.parquet', '2025_12_25.parquet', '2025_12_01.parquet', '2025_11_06.parquet', '2025_12_24.parquet', '2026_01_13.parquet', '2025_12_16.parquet', '2026_01_23.parquet', '2025_12_05.parquet', '2025_11_05.parquet', '2026_02_02.parquet', '2025_12_26.parquet', '2025_12_10.parquet', '2025_12_12.parquet', '2026_01_08.parquet', '2025_12_02.parquet', '2025_12_18.parquet', '2026_01_26.parquet', '2025_12_09.parquet', '2025_11_03.parquet']\n",
      "['daily_20250924.parquet', 'daily_20250730.parquet', 'daily_20250709.parquet', 'daily_20250827.parquet', 'daily_20250613.parquet', 'daily_20250213.parquet', 'daily_20250910.parquet', 'daily_20250508.parquet', 'daily_20250605.parquet', 'daily_20250813.parquet', 'daily_20251209.parquet', 'daily_20251204.parquet', 'daily_20250825.parquet', 'daily_20250123.parquet', 'daily_20250911.parquet', 'daily_20250815.parquet', 'daily_20250707.parquet', 'daily_20250923.parquet', 'daily_20250425.parquet', 'daily_20250930.parquet', 'daily_20251104.parquet', 'daily_20250515.parquet', 'daily_20250306.parquet', 'daily_20251029.parquet', 'daily_20250113.parquet', 'daily_20251114.parquet', 'daily_20250909.parquet', 'daily_20250314.parquet', 'daily_20260109.parquet', 'daily_20251024.parquet', 'daily_20260122.parquet', 'daily_20250403.parquet', 'daily_20260121.parquet', 'daily_20250207.parquet', 'daily_20250604.parquet', 'daily_20250514.parquet', 'daily_20260129.parquet', 'daily_20250806.parquet', 'daily_20250611.parquet', 'daily_20250325.parquet', 'daily_20250415.parquet', 'daily_20250304.parquet', 'daily_20250701.parquet', 'daily_20250107.parquet', 'daily_20260202.parquet', 'daily_20251225.parquet', 'daily_20250220.parquet', 'daily_20250715.parquet', 'daily_20250702.parquet', 'daily_20250127.parquet', 'daily_20250320.parquet', 'daily_20250828.parquet', 'daily_20250311.parquet', '__pycache__', 'daily_20251009.parquet', 'daily_20260107.parquet', 'daily_20250725.parquet', 'daily_20250721.parquet', 'daily_20251022.parquet', 'daily_20251215.parquet', 'daily_20250603.parquet', 'daily_20250908.parquet', 'daily_20251216.parquet', 'daily_20251031.parquet', 'daily_20250114.parquet', 'daily_20250728.parquet', 'daily_20250620.parquet', 'daily_20250926.parquet', 'daily_20250307.parquet', 'daily_20250109.parquet', 'daily_20260114.parquet', 'daily_20250326.parquet', 'daily_20250310.parquet', 'daily_20250327.parquet', 'daily_20251106.parquet', 'daily_20251126.parquet', 'daily_20250918.parquet', 'daily_20260123.parquet', 'daily_20260112.parquet', 'daily_20250829.parquet', 'daily_20250917.parquet', 'daily_20251124.parquet', 'daily_20250912.parquet', 'daily_20250117.parquet', 'daily_20250804.parquet', 'daily_20250703.parquet', 'daily_20250523.parquet', 'daily_20251027.parquet', 'daily_20250206.parquet', 'daily_20250115.parquet', 'daily_20250808.parquet', 'daily_20260116.parquet', 'daily_20251212.parquet', 'daily_20250210.parquet', 'daily_20251201.parquet', 'daily_20251230.parquet', 'daily_20251203.parquet', 'daily_20251229.parquet', 'daily_20250610.parquet', 'daily_20250313.parquet', 'daily_20250904.parquet', 'daily_20250407.parquet', 'daily_20250609.parquet', 'daily_20251224.parquet', 'daily_20251014.parquet', 'daily_20251127.parquet', 'daily_20250711.parquet', 'daily_20250225.parquet', 'daily_20250718.parquet', 'daily_20251028.parquet', 'daily_20250418.parquet', 'daily_20250714.parquet', 'daily_20250619.parquet', 'daily_20250416.parquet', 'daily_20250527.parquet', 'daily_20250522.parquet', 'daily_20260120.parquet', 'test', 'daily_20250606.parquet', 'daily_20250124.parquet', 'daily_20250821.parquet', 'daily_20250819.parquet', 'daily_20250226.parquet', 'daily_20251023.parquet', 'daily_20250422.parquet', 'daily_20250211.parquet', 'daily_20260108.parquet', 'daily_20250530.parquet', 'daily_20250324.parquet', 'daily_20251218.parquet', 'daily_20250408.parquet', 'daily_20250618.parquet', 'daily_20250214.parquet', 'daily_20251118.parquet', 'daily_20250820.parquet', 'daily_20250624.parquet', 'daily_20250818.parquet', 'daily_20250321.parquet', 'daily_20260126.parquet', 'daily_20250218.parquet', 'daily_20250521.parquet', 'daily_20250319.parquet', 'daily_20250805.parquet', 'daily_20260113.parquet', 'daily_20250916.parquet', 'daily_20250409.parquet', 'daily_20260105.parquet', 'daily_20260106.parquet', 'daily_20250430.parquet', 'daily_20251117.parquet', 'daily_20250414.parquet', 'daily_20250429.parquet', 'daily_20250228.parquet', 'daily_20250630.parquet', 'daily_20250205.parquet', 'daily_20251125.parquet', 'daily_20250710.parquet', 'daily_20250903.parquet', 'daily_20250512.parquet', 'daily_20250120.parquet', 'daily_20250922.parquet', 'daily_20250513.parquet', 'daily_20250506.parquet', 'daily_20250110.parquet', 'daily_20250317.parquet', 'daily_20250428.parquet', 'daily_20250801.parquet', 'daily_20250121.parquet', 'daily_20250103.parquet', 'daily_20250318.parquet', 'daily_20250717.parquet', 'daily_20260127.parquet', 'daily_20260205.parquet', 'daily_20250224.parquet', 'daily_20250704.parquet', 'daily_20251119.parquet', 'daily_20260204.parquet', 'daily_20250807.parquet', 'daily_20250423.parquet', 'daily_20250612.parquet', 'daily_20250529.parquet', 'daily_20250312.parquet', 'daily_20250108.parquet', 'daily_20251020.parquet', 'daily_20260119.parquet', 'daily_20250627.parquet', 'daily_20250902.parquet', 'daily_20251231.parquet', 'daily_20251120.parquet', 'daily_20250901.parquet', 'daily_20250616.parquet', 'daily_20250219.parquet', 'daily_20250106.parquet', 'daily_20250101_20260208.parquet', 'daily_20251013.parquet', 'daily_20250822.parquet', 'daily_20251021.parquet', 'daily_20251226.parquet', 'daily_20250303.parquet', 'daily_20251107.parquet', 'daily_20260130.parquet', 'daily_20250509.parquet', 'daily_20251205.parquet', 'daily_20250221.parquet', 'daily_20250729.parquet', 'daily_20251016.parquet', 'daily_20251223.parquet', 'daily_20250826.parquet', 'daily_20250410.parquet', 'daily_20251110.parquet', 'daily_20250925.parquet', 'daily_20251015.parquet', 'daily_20250519.parquet', 'daily_20250516.parquet', 'daily_20251202.parquet', 'daily_20250724.parquet', 'daily_20251121.parquet', 'daily_20250328.parquet', 'daily_20251105.parquet', 'daily_20250528.parquet', 'daily_20250625.parquet', 'daily_20251103.parquet', 'daily_20250421.parquet', 'daily_20250212.parquet', 'daily_20251208.parquet', 'daily_20250731.parquet', 'daily_20250102.parquet', 'daily_20250723.parquet', 'daily_20250722.parquet', 'daily_20250402.parquet', 'daily_20250217.parquet', 'daily_20250305.parquet', 'daily_20250626.parquet', 'daily_20250507.parquet', 'daily_20250814.parquet', 'daily_20260115.parquet', 'daily_20250424.parquet', 'daily_20251030.parquet', 'daily_20250417.parquet', 'daily_20250623.parquet', 'daily_20250617.parquet', 'daily_20251112.parquet', 'daily_20251113.parquet', 'daily_20251219.parquet', 'daily_20250227.parquet', 'daily_20250915.parquet', 'daily_20251128.parquet', 'daily_20250411.parquet', 'daily_20250929.parquet', 'daily_20250811.parquet', 'daily_20250708.parquet', 'daily_20250122.parquet', 'daily_20251211.parquet', 'daily_20250526.parquet', 'daily_20251017.parquet', 'daily_20250116.parquet', 'daily_20251010.parquet', 'daily_20251111.parquet', 'daily_20251210.parquet', 'daily_20250716.parquet', 'daily_20250919.parquet', 'daily_20260206.parquet', 'daily_20250812.parquet', 'daily_20250905.parquet', 'daily_20260203.parquet', 'daily_20251217.parquet', 'daily_20250331.parquet', 'daily_20250520.parquet', 'daily_20260128.parquet', 'daily_20250401.parquet', 'daily_20251222.parquet']\n",
      "        ts_code trade_date   open   high    low  close  pre_close  change  \\\n",
      "0     000001.SZ   20250102  11.73  11.77  11.39  11.43      11.70   -0.27   \n",
      "1     000002.SZ   20250102   7.25   7.36   7.07   7.11       7.26   -0.15   \n",
      "2     000004.SZ   20250102  13.73  14.39  13.33  14.18      13.84    0.34   \n",
      "3     000006.SZ   20250102   7.23   7.52   7.18   7.25       7.32   -0.07   \n",
      "4     000007.SZ   20250102   7.00   7.27   6.94   7.02       7.03   -0.01   \n",
      "...         ...        ...    ...    ...    ...    ...        ...     ...   \n",
      "5364  920111.BJ   20250102  23.47  24.42  23.47  23.78      23.92   -0.14   \n",
      "5365  920116.BJ   20250102  45.00  46.87  35.00  35.10       6.92   28.18   \n",
      "5366  920118.BJ   20250102  24.21  25.08  24.12  24.49      24.40    0.09   \n",
      "5367  920128.BJ   20250102  28.66  29.33  27.88  28.99      28.78    0.21   \n",
      "5368  302132.SZ   20250102  71.01  71.48  66.75  67.24      71.78   -4.54   \n",
      "\n",
      "       pct_chg         vol       amount  \n",
      "0      -2.3077  1819596.99  2102923.078  \n",
      "1      -2.0661  1182666.05   854487.563  \n",
      "2       2.4566   119760.37   167987.024  \n",
      "3      -0.9563   307195.10   225252.942  \n",
      "4      -0.1422    68219.01    48456.355  \n",
      "...        ...         ...          ...  \n",
      "5364   -0.5853    20165.05    48340.491  \n",
      "5365  407.2254   222896.93   876661.507  \n",
      "5366    0.3689     4213.82    10395.546  \n",
      "5367    0.7297    10330.51    29640.110  \n",
      "5368   -6.3249   167425.19  1153350.246  \n",
      "\n",
      "[5369 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "factor_dir = './factor/high_frequency/'\n",
    "daily_dir = './daily_data/daily/'\n",
    "print(os.listdir(factor_dir))\n",
    "print(os.listdir(daily_dir))\n",
    "tdf = pd.read_parquet(factor_dir+'2026_01_09.parquet')\n",
    "daily_df = pd.read_parquet(daily_dir+'daily_20250102.parquet')\n",
    "print(daily_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试get_local_data函数\n",
      "['000001.SZ' '000002.SZ' '000004.SZ' ... '920118.BJ' '920128.BJ'\n",
      " '302132.SZ']\n",
      "ts_code     000001.SZ  000002.SZ  000004.SZ  000006.SZ  000007.SZ  000008.SZ  \\\n",
      "date                                                                           \n",
      "2025-01-02      11.43       7.11      14.18       7.25       7.02       2.84   \n",
      "2025-01-03      11.38       7.00      12.80       6.91       6.60       2.65   \n",
      "2025-01-06      11.44       6.98      12.52       6.70       6.63       2.58   \n",
      "2025-01-07      11.51       7.05      13.11       6.85       6.93       2.66   \n",
      "2025-01-08      11.50       6.96      13.40       6.96       6.93       2.64   \n",
      "2025-01-09      11.40       6.95      13.26       6.90       7.13       2.65   \n",
      "2025-01-10      11.30       6.69      12.51       6.72       6.77       2.71   \n",
      "\n",
      "ts_code     000009.SZ  000010.SZ  000011.SZ  000012.SZ  ...  920964.BJ  \\\n",
      "date                                                    ...              \n",
      "2025-01-02       8.90       2.71       8.62       5.14  ...       6.93   \n",
      "2025-01-03       8.72       2.64       8.27       5.08  ...       6.80   \n",
      "2025-01-06       8.74       2.64       8.30       5.12  ...       6.49   \n",
      "2025-01-07       8.73       2.90       8.53       5.09  ...       6.60   \n",
      "2025-01-08       8.63       2.96       8.45       5.06  ...       6.62   \n",
      "2025-01-09       8.58       2.96       8.43       4.99  ...       7.11   \n",
      "2025-01-10       8.40       2.98       8.16       4.91  ...       6.73   \n",
      "\n",
      "ts_code     920970.BJ  920971.BJ  920974.BJ  920976.BJ  920978.BJ  920981.BJ  \\\n",
      "date                                                                           \n",
      "2025-01-02       5.65      26.50       6.94      18.80      13.30      25.70   \n",
      "2025-01-03       5.77      26.16       7.27      18.51      13.26      26.00   \n",
      "2025-01-06       5.80      24.86       7.25      17.56      13.18      26.99   \n",
      "2025-01-07       5.91      25.40       7.69      18.11      13.54      27.57   \n",
      "2025-01-08       5.95      27.18       7.63      18.36      13.83      27.54   \n",
      "2025-01-09       6.02      27.74       7.58      19.63      13.82      28.88   \n",
      "2025-01-10       5.75      25.14       7.24      19.20      14.05      27.48   \n",
      "\n",
      "ts_code     920982.BJ  920985.BJ  920992.BJ  \n",
      "date                                         \n",
      "2025-01-02     205.90       9.89      13.29  \n",
      "2025-01-03     209.32       9.82      12.95  \n",
      "2025-01-06     216.62      10.04      13.15  \n",
      "2025-01-07     214.51      10.18      13.27  \n",
      "2025-01-08     217.72      10.09      13.57  \n",
      "2025-01-09     215.69      10.18      13.71  \n",
      "2025-01-10     220.82       9.28      12.88  \n",
      "\n",
      "[7 rows x 5369 columns]\n"
     ]
    }
   ],
   "source": [
    "print('测试get_local_data函数')\n",
    "from mylib.get_local_data import get_local_data\n",
    "daily_df = pd.read_parquet(daily_dir+'daily_20250102.parquet')\n",
    "demo_df = daily_df['ts_code'].unique()\n",
    "# demo_df = ['000001.SZ','000002.SZ','7654321.SZ']\n",
    "print(demo_df)\n",
    "data_df = get_local_data(demo_df, '20250102', '20251210')\n",
    "print(data_df)\n",
    "# print(get_local_data())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据加载与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 数据配置 ====================\n",
    "FACTOR_DIR = \"/data1/code_git/tick_data_analysis/factor/daily\"\n",
    "OUTPUT_DIR = \"./hf_analysis_results\"\n",
    "\n",
    "class HighFrequencyFactorAnalyzer:\n",
    "    \"\"\"高频因子分析器\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.hf_factors = [\n",
    "            'order_imbalance', 'effective_spread', 'realized_volatility',\n",
    "            'bid_ask_spread', 'vwap_deviation', 'price_momentum',\n",
    "            'trade_flow_intensity', 'micro_price', 'trade_imbalance',\n",
    "            'depth_imbalance'\n",
    "        ]\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载因子数据\"\"\"\n",
    "        print(\"=\"*60)\n",
    "        print(\"加载高频因子数据\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        files = sorted(Path(FACTOR_DIR).glob(\"zz1000_factors_*.parquet\"))\n",
    "        print(f\"发现 {len(files)} 个文件\")\n",
    "\n",
    "        all_df = []\n",
    "        for i, f in enumerate(files):\n",
    "            if (i+1) % 5 == 0:\n",
    "                print(f\"  加载: {i+1}/{len(files)}\")\n",
    "            df = pd.read_parquet(f)\n",
    "            all_df.append(df)\n",
    "\n",
    "        self.raw = pd.concat(all_df, ignore_index=True)\n",
    "        self.hf_factors = [f for f in self.hf_factors if f in self.raw.columns]\n",
    "\n",
    "        print(f\"\\n原始数据: {len(self.raw):,} 条\")\n",
    "        print(f\"股票数: {self.raw['stock_code'].nunique()}\")\n",
    "        print(f\"日期: {self.raw['date'].min()} ~ {self.raw['date'].max()}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def aggregate_daily(self):\n",
    "        \"\"\"聚合日度因子\"\"\"\n",
    "        print(\"\\n聚合日度因子...\")\n",
    "\n",
    "        df = self.raw.copy()\n",
    "\n",
    "        # 按股票-日期聚合\n",
    "        agg_dict = {f: ['mean', 'std'] for f in self.hf_factors}\n",
    "        daily = df.groupby(['stock_code', 'date']).agg(agg_dict)\n",
    "        daily.columns = [f\"{c[0]}_{c[1]}\" for c in daily.columns]\n",
    "        daily = daily.reset_index()\n",
    "\n",
    "        # 价格信息\n",
    "        price = df.groupby(['stock_code', 'date']).agg({\n",
    "            'lastPrice': ['first', 'last'], 'open': 'first'\n",
    "        }).reset_index()\n",
    "        price.columns = ['stock_code', 'date', 'first', 'last', 'open']\n",
    "\n",
    "        self.daily = pd.merge(daily, price, on=['stock_code', 'date'])\n",
    "        self.daily['return'] = self.daily['last'] / self.daily['first'] - 1\n",
    "\n",
    "        print(f\"日度因子: {len(self.daily):,} 条, {self.daily['stock_code'].nunique()} 只\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def calc_future_returns(self, periods=[1, 5, 10, 20]):\n",
    "        \"\"\"计算未来收益\"\"\"\n",
    "        print(\"\\n计算未来收益...\")\n",
    "\n",
    "        df = self.daily.sort_values(['stock_code', 'date'])\n",
    "\n",
    "        for p in periods:\n",
    "            df[f'ret_{p}d'] = df.groupby('stock_code')['return'].transform(\n",
    "                lambda x: x.shift(-1).rolling(p).sum().shift(-p+1)\n",
    "            )\n",
    "\n",
    "        self.data = df\n",
    "        print(f\"合并数据: {len(df):,} 条\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def calc_ic(self, ret_col='ret_1d'):\n",
    "        \"\"\"计算IC\"\"\"\n",
    "        print(f\"\\nIC分析 ({ret_col})...\")\n",
    "\n",
    "        ic = {}\n",
    "        for f in self.hf_factors:\n",
    "            col = f\"{f}_mean\"\n",
    "            valid = self.data[['stock_code', col, ret_col]].dropna()\n",
    "\n",
    "            if len(valid) < 100:\n",
    "                continue\n",
    "\n",
    "            ic_val = valid[col].corr(valid[ret_col])\n",
    "            n = len(valid)\n",
    "            t = ic_val * np.sqrt((n-2)/(1-ic_val**2+1e-10))\n",
    "            p = 2 * (1 - stats.t.cdf(abs(t), n-2))\n",
    "            sp, _ = stats.spearmanr(valid[col], valid[ret_col])\n",
    "\n",
    "            ic[f] = {'IC': ic_val, 'RankIC': sp, 'IC_abs': abs(ic_val), 'P': p, 'N': n}\n",
    "\n",
    "        self.ic = pd.DataFrame(ic).T.sort_values('IC_abs', ascending=False)\n",
    "\n",
    "        print(\"\\nIC结果:\")\n",
    "        print(\"-\"*70)\n",
    "        print(f\"{'因子':<20} {'IC':>8} {'RankIC':>8} {'|IC|':>8} {'P值':>10} {'显著':>6}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        for idx, row in self.ic.iterrows():\n",
    "            sig = '***' if row['P'] < 0.001 else '**' if row['P'] < 0.01 else '*' if row['P'] < 0.05 else ''\n",
    "            print(f\"{idx:<20} {row['IC']:>8.4f} {row['RankIC']:>8.4f} {row['IC_abs']:>8.4f} {row['P']:>10.4f} {sig:>6}\")\n",
    "\n",
    "        return self.ic\n",
    "\n",
    "    def calc_ic_periods(self):\n",
    "        \"\"\"多持有期IC\"\"\"\n",
    "        print(\"\\n多持有期IC...\")\n",
    "\n",
    "        all_ic = {}\n",
    "        for p in [1, 5, 10, 20]:\n",
    "            ret = f'ret_{p}d'\n",
    "            for f in self.hf_factors:\n",
    "                col = f\"{f}_mean\"\n",
    "                key = f\"{f}_{p}d\"\n",
    "                valid = self.data[['stock_code', col, ret]].dropna()\n",
    "                if len(valid) > 100:\n",
    "                    all_ic[key] = valid[col].corr(valid[ret])\n",
    "\n",
    "        self.ic_periods = pd.DataFrame(all_ic, index=[0]).T\n",
    "\n",
    "        # 透视表\n",
    "        data = [(k.rsplit('_', 1)[0], k.rsplit('_', 1)[1].replace('d', ''), v)\n",
    "                for k, v in all_ic.items()]\n",
    "        pivot = pd.DataFrame(data, columns=['factor', 'period', 'IC']).pivot(\n",
    "            index='factor', columns='period', values='IC')\n",
    "        print(pivot.round(4))\n",
    "\n",
    "        return self.ic_periods\n",
    "\n",
    "    def ranking_analysis(self, ret_col='ret_1d'):\n",
    "        \"\"\"分层回测\"\"\"\n",
    "        print(\"\\n分层回测...\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for f in self.hf_factors:\n",
    "            col = f\"{f}_mean\"\n",
    "            valid = self.data[['stock_code', col, ret_col]].dropna()\n",
    "\n",
    "            if len(valid) < 100:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                valid['g'] = pd.qcut(valid[col], 5, labels=False, duplicates='drop')\n",
    "                grp = valid.groupby('g')[ret_col].mean()\n",
    "                ls = grp.iloc[-1] - grp.iloc[0]\n",
    "                dir_ = '正向' if grp.iloc[-1] > grp.iloc[0] else '负向'\n",
    "                ic_val = self.ic.loc[f, 'IC'] if f in self.ic.index else 0\n",
    "\n",
    "                results.append({\n",
    "                    '因子': f, 'IC': ic_val, '多空': ls*100,\n",
    "                    '方向': dir_, 'Q1': grp.iloc[0]*100, 'Q5': grp.iloc[-1]*100\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        self.ranking = pd.DataFrame(results).sort_values('多空', ascending=False)\n",
    "\n",
    "        print(\"\\n结果:\")\n",
    "        print(\"-\"*80)\n",
    "        print(f\"{'因子':<20} {'IC':>8} {'多空':>10} {'方向':>6} {'Q1':>10} {'Q5':>10}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        for _, r in self.ranking.iterrows():\n",
    "            print(f\"{r['因子']:<20} {r['IC']:>8.4f} {r['多空']:>8.2f}% {r['方向']:>6} {r['Q1']:>9.2f}% {r['Q5']:>9.2f}%\")\n",
    "\n",
    "        return self.ranking\n",
    "\n",
    "    def visualize(self):\n",
    "        \"\"\"可视化\"\"\"\n",
    "        Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "        # IC柱状图\n",
    "        ax1 = axes[0, 0]\n",
    "        ic_s = self.ic.sort_values('IC')\n",
    "        c = ['g' if x > 0 else 'r' for x in ic_s['IC']]\n",
    "        ax1.barh(range(len(ic_s)), ic_s['IC'], color=c, alpha=0.7)\n",
    "        ax1.set_yticks(range(len(ic_s)))\n",
    "        ax1.set_yticklabels(ic_s.index, fontsize=9)\n",
    "        ax1.axvline(0, c='k', lw=0.5)\n",
    "        ax1.set_title('Factor IC')\n",
    "\n",
    "        # |IC|排名\n",
    "        ax2 = axes[0, 1]\n",
    "        ic_a = self.ic.sort_values('IC_abs', ascending=True)\n",
    "        ax2.barh(range(len(ic_a)), ic_a['IC_abs'], color='steelblue', alpha=0.7)\n",
    "        ax2.set_yticks(range(len(ic_a)))\n",
    "        ax2.set_yticklabels(ic_a.index, fontsize=9)\n",
    "        ax2.axvline(0.02, c='r', ls='--', lw=1)\n",
    "        ax2.set_title('|IC| Ranking')\n",
    "\n",
    "        # 多持有期IC\n",
    "        ax3 = axes[1, 0]\n",
    "        data = [(k.rsplit('_', 1)[0], k.rsplit('_', 1)[1].replace('d', ''), v)\n",
    "                for k, v in self.ic_periods[0].items()]\n",
    "        piv = pd.DataFrame(data, columns=['f', 'p', 'v']).pivot(index='f', columns='p', values='v')\n",
    "        sns.heatmap(piv, annot=True, fmt='.3f', cmap='RdYlGn', center=0, ax=ax3)\n",
    "        ax3.set_title('IC Across Periods')\n",
    "\n",
    "        # 分层回测\n",
    "        ax4 = axes[1, 1]\n",
    "        top = self.ranking.head(8)\n",
    "        c = ['g' if x > 0 else 'r' for x in top['多空']]\n",
    "        ax4.barh(range(len(top)), top['多空'], color=c, alpha=0.7)\n",
    "        ax4.set_yticks(range(len(top)))\n",
    "        ax4.set_yticklabels(top['因子'], fontsize=9)\n",
    "        ax4.axvline(0, c='k', lw=0.5)\n",
    "        ax4.set_title('Long-Short Return')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{OUTPUT_DIR}/hf_analysis.png\", dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"\\n图已保存: {OUTPUT_DIR}/hf_analysis.png\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"完整流程\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"中证1000高频因子分析\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        self.load_data()\n",
    "        self.aggregate_daily()\n",
    "        self.calc_future_returns()\n",
    "        self.calc_ic()\n",
    "        self.calc_ic_periods()\n",
    "        self.ranking_analysis()\n",
    "        self.visualize()\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"完成!\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "print(\"分析器定义完成!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 运行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行完整分析\n",
    "analyzer = HighFrequencyFactorAnalyzer()\n",
    "analyzer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 核心发现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"核心发现\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 最强因子\n",
    "print(\"\\n【最强正向因子】(因子值高 → 收益高)\")\n",
    "pos = analyzer.ic[analyzer.ic['IC'] > 0].head(3)\n",
    "for idx, row in pos.iterrows():\n",
    "    print(f\"  {idx}: IC={row['IC']:.4f}\")\n",
    "\n",
    "print(\"\\n【最强负向因子】(因子值高 → 收益低)\")\n",
    "neg = analyzer.ic[analyzer.ic['IC'] < 0].head(3)\n",
    "for idx, row in neg.iterrows():\n",
    "    print(f\"  {idx}: IC={row['IC']:.4f}\")\n",
    "\n",
    "print(\"\\n【分层回测TOP5】\")\n",
    "top5 = analyzer.ranking.head(5)\n",
    "for _, r in top5.iterrows():\n",
    "    print(f\"  {r['因子']}: 多空={r['多空']:.2f}%, IC={r['IC']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 结论与策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "=\"*80\n",
    "策略建议\n",
    "=\"*80\n",
    "\n",
    "【1. 订单流因子】\n",
    "-----------------\n",
    "- order_imbalance: IC=-0.036 (负向)\n",
    "  → 买方压力(OI>0)后价格倾向下跌\n",
    "  → 可用于反向操作\n",
    "\n",
    "【2. 波动率因子】\n",
    "-----------------\n",
    "- realized_volatility: IC=+0.022 (正向)\n",
    "  → 高波动股票短期收益反而更高\n",
    "  → 反映风险溢价\n",
    "\n",
    "【3. 流动性因子】\n",
    "-----------------\n",
    "- bid_ask_spread: IC=-0.006 (负向, 不显著)\n",
    "  → 高价差股票流动性差\n",
    "  → 交易成本较高\n",
    "\n",
    "【4. 价格偏离因子】\n",
    "-----------------\n",
    "- vwap_deviation: IC=-0.011 (负向)\n",
    "  → 价格偏离VWAP后倾向于回归\n",
    "  → 日内反转交易机会\n",
    "\n",
    "【5. 动量因子】\n",
    "-----------------\n",
    "- price_momentum: IC=+0.004 (微弱正向)\n",
    "  → 短期动量效应不明显\n",
    "  → 长期(20天)IC增至0.039\n",
    "\n",
    "【日内交易策略】\n",
    "-----------------\n",
    "1. 观察order_imbalance变化\n",
    "2. 价格偏离VWAP时反向操作\n",
    "3. 高波动股票设置更宽止损\n",
    "4. 避免高bid_ask_spread的股票\n",
    "\n",
    "【风险提示】\n",
    "-----------------\n",
    "1. 高频因子收益可能被交易成本侵蚀\n",
    "2. 需考虑滑点和冲击成本\n",
    "3. 不同市场环境下因子表现可能有差异\n",
    "\"\"\")\n",
    "\n",
    "# 保存结果\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "analyzer.ic.to_csv(f\"{OUTPUT_DIR}/hf_ic.csv\")\n",
    "analyzer.ranking.to_csv(f\"{OUTPUT_DIR}/hf_ranking.csv\", index=False)\n",
    "analyzer.ic_periods.to_csv(f\"{OUTPUT_DIR}/hf_ic_periods.csv\")\n",
    "\n",
    "print(f\"\\n结果已保存至: {OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 总结\n",
    "\n",
    "| 因子 | IC | 评级 | 策略 |\n",
    "|------|-----|------|------|\n",
    "| order_imbalance | -0.036 | A级 | 反向操作 |\n",
    "| depth_imbalance | -0.036 | A级 | 反向操作 |\n",
    "| trade_flow_intensity | +0.025 | B级 | 高流强=高收益 |\n",
    "| realized_volatility | +0.022 | B级 | 高波=高收益(风险溢价) |\n",
    "| vwap_deviation | -0.011 | C级 | 日内反转 |\n",
    "| price_momentum | +0.004 | D级 | 长期动量 |\n",
    "\n",
    "**核心结论**: 高频因子以短期反转效应为主，订单不平衡是最强预测因子。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
